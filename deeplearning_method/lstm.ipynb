{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD8iESLfnEIe"
      },
      "outputs": [],
      "source": [
        "!pip install pandas keras tensorflow nltk scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "hHf8n_I2nE56"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import nltk\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/workspaces/NLP-sesion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "xPoNkqmWrCoZ"
      },
      "outputs": [],
      "source": [
        "from process_data import ProcessData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "74gx53TNnGgF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_29213/2734294764.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['sentiment'] = df['sentiment'].replace({'positive': 1, 'negative': 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2250 750 2250 750\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv(\"/workspaces/NLP-sesion/IMDBDataset.csv\", nrows=3000)\n",
        "\n",
        "df['sentiment'] = df['sentiment'].replace({'positive': 1, 'negative': 0})\n",
        "processor = ProcessData(df, \"review\", \"sentiment\")\n",
        "\n",
        "df = processor.data_cleaning()\n",
        "X_train, X_test, y_train, y_test  = processor.data_split()\n",
        "print(len(X_train), len(X_test), len(y_train), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab Size: 28669\n"
          ]
        }
      ],
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "vocab_size=len(tokenizer.word_index)+1\n",
        "print(f'Vocab Size: {vocab_size}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_words = 30\n",
        "\n",
        "X_train=pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_words, padding=\"post\")\n",
        "X_test=pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_words, padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "5v1EnUH8qleO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/NLP-sesion/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - accuracy: 0.5433 - loss: 0.6925 - val_accuracy: 0.6027 - val_loss: 0.6883\n",
            "Epoch 2/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - accuracy: 0.7753 - loss: 0.6733 - val_accuracy: 0.6827 - val_loss: 0.6091\n",
            "Epoch 3/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.7964 - loss: 0.4656 - val_accuracy: 0.6973 - val_loss: 0.6175\n",
            "Epoch 4/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.9349 - loss: 0.1933 - val_accuracy: 0.7160 - val_loss: 0.7856\n",
            "Epoch 5/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - accuracy: 0.9735 - loss: 0.0715 - val_accuracy: 0.7293 - val_loss: 0.8260\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x76768397f920>"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an LSTM model with an Embedding layer and fit training data\n",
        "model=Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size,output_dim=100,input_length=30))\n",
        "model.add(layers.Bidirectional(layers.LSTM(128)))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='BinaryCrossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=256, epochs=5,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  10  116    1   14   18    1  129   12   10   65  116   26   27    1\n",
            "   322 1487  351   37    1 3484    0    0    0    0    0]]\n"
          ]
        }
      ],
      "source": [
        "sentence_to_test = \"I loved the movie, but the scenes that i really loved was one the actor threw himself from the helicopter\"\n",
        "sentiment = 1\n",
        "\n",
        "df = pd.DataFrame([[sentence_to_test, sentiment]], columns=['review', 'sentiment'])\n",
        "test_processor = ProcessData(df, \"review\", \"sentiment\")\n",
        "\n",
        "cleaned_sentence = test_processor.data_cleaning()\n",
        "sentence_seq = tokenizer.texts_to_sequences(cleaned_sentence)  # convert to sequence\n",
        "preprocessed_sentence = pad_sequences(sentence_seq, maxlen=25, padding=\"post\") \n",
        "print(preprocessed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "yQ2vPZ_8q0F1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.8668538], dtype=float32)"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make a prediction\n",
        "prediction = model(preprocessed_sentence, training=False)\n",
        "\n",
        "prediction.numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
